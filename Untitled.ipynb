{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fly/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,148,485\n",
      "Trainable params: 1,147,589\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/fly/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 381s 38s/step - loss: 0.5233 - acc: 0.8250 - val_loss: 4.8640 - val_acc: 0.4700 ETA: 1:20 - loss: 0.5892 - acc: 0.8\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.86400, saving model to ./model.h5\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.1591 - acc: 0.9375 - val_loss: 4.5590 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.86400 to 4.55902, saving model to ./model.h5\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.1431 - acc: 0.8525 - val_loss: 1.4376 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.55902 to 1.43765, saving model to ./model.h5\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.1097 - acc: 0.8700 - val_loss: 3.5633 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.43765\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 160s 16s/step - loss: 0.0987 - acc: 0.8700 - val_loss: 4.6402 - val_acc: 0.2800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.43765\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 158s 16s/step - loss: 0.0822 - acc: 0.8725 - val_loss: 1.8745 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.43765\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0384 - acc: 0.8925 - val_loss: 2.3529 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.43765\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 158s 16s/step - loss: 0.0363 - acc: 0.8900 - val_loss: 1.0014 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.43765 to 1.00136, saving model to ./model.h5\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 162s 16s/step - loss: 0.0327 - acc: 0.8875 - val_loss: 0.6465 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00136 to 0.64654, saving model to ./model.h5\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.0223 - acc: 0.8925 - val_loss: 0.3230 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.64654 to 0.32297, saving model to ./model.h5\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.0379 - acc: 0.8875 - val_loss: 1.0474 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32297\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.0307 - acc: 0.9900 - val_loss: 1.2798 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32297\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.0569 - acc: 0.8800 - val_loss: 2.0296 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.32297\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0560 - acc: 0.8800 - val_loss: 2.2851 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32297\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 158s 16s/step - loss: 0.0762 - acc: 0.8775 - val_loss: 0.5334 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32297\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0794 - acc: 0.8825 - val_loss: 1.2243 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32297\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0312 - acc: 0.8950 - val_loss: 3.8568 - val_acc: 0.3900\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32297\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0439 - acc: 0.8850 - val_loss: 2.3446 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32297\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0334 - acc: 0.8875 - val_loss: 1.1787 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.32297\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0453 - acc: 0.8775 - val_loss: 0.4791 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.32297\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0241 - acc: 0.8925 - val_loss: 0.5618 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.32297\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0438 - acc: 0.8900 - val_loss: 0.2895 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.32297 to 0.28951, saving model to ./model.h5\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0465 - acc: 0.9875 - val_loss: 0.5263 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28951\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0332 - acc: 0.9850 - val_loss: 0.4670 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28951\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0157 - acc: 0.9000 - val_loss: 0.3693 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.28951\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0236 - acc: 0.8925 - val_loss: 0.2807 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.28951 to 0.28068, saving model to ./model.h5\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.2162 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.28068 to 0.21624, saving model to ./model.h5\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 158s 16s/step - loss: 0.0099 - acc: 0.8950 - val_loss: 0.2772 - val_acc: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 0.21624\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0074 - acc: 0.9000 - val_loss: 0.5431 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.21624\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.0142 - acc: 0.8925 - val_loss: 0.2617 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.21624\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 159s 16s/step - loss: 0.0069 - acc: 0.9000 - val_loss: 0.4340 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21624\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 166s 17s/step - loss: 0.0096 - acc: 0.8975 - val_loss: 0.1290 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.21624 to 0.12899, saving model to ./model.h5\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 169s 17s/step - loss: 0.0103 - acc: 0.8950 - val_loss: 0.4391 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12899\n",
      "Epoch 34/100\n",
      " 8/10 [=======================>......] - ETA: 33s - loss: 0.0104 - acc: 0.9969"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"    ###这两句代码用来关闭CUDA加速\n",
    "from keras.models import Input,Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "img_h,img_w,n_channels = 128,128,3 ####图像高，宽，通道数\n",
    "classes = 5 ###类别\n",
    "train_batch_size = 40  #####训练batch大小\n",
    "test_batch_size= 20   #####测试batch大小，本次实验用作验证集\n",
    "train_path = './all_data/train/*'\n",
    "test_path = './all_data/test/*'\n",
    "def get_one_hot(num,classes):  ###得到one-hot编码   也可用keras自带函数np_utils.to_categorical()\n",
    "    one_hot = np.zeros(shape=(1,classes))\n",
    "    one_hot[:,num] = 1\n",
    "    return one_hot\n",
    "class data_generate():  ####数据生成器，可以实时对数据做变化，可用于数据集比较大的情况\n",
    "    def __init__(self,img_path,img_h,img_w,n_channels,batch_size=1,flip=True):\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.n_channels = n_channels\n",
    "        self.flip = flip    ###是否做水平或者垂直翻转\n",
    "        self.all_path = glob.glob(img_path)\n",
    "        self.all_num = len(self.all_path)\n",
    "        self.index = 0\n",
    "        self.batch_size = batch_size\n",
    "    def get_batch(self,index,size):   ####得到数据和对应的label\n",
    "        all_data = np.zeros(shape=(size,self.img_h,self.img_w,self.n_channels),dtype='float32')\n",
    "        all_label = np.zeros(shape=(size,classes))\n",
    "        for i,img_name in enumerate(self.all_path[index:index+size]):\n",
    "            img = cv2.imread(img_name,1)\n",
    "            #print(img_name)\n",
    "            img = cv2.resize(img,dsize=(img_w,img_h))###归一化图片输入尺寸\n",
    "            img = img -128.0  ####数据归一到【-1,1】\n",
    "            img = img /128.0\n",
    "            if self.flip:\n",
    "                p = np.random.random()\n",
    "                if p>0.5:\n",
    "                    p_v_h = np.random.random()\n",
    "                    if p_v_h>0.5:\n",
    "                        img = img[:,::-1,:] ##水平翻转\n",
    "                    else:\n",
    "                        img = img[::-1,:, :]  ##垂直翻转\n",
    "            all_data[i,:,:,:] = img\n",
    "            label = int(list(img_name)[-7])-3\n",
    "            all_label[i,:] = get_one_hot(label,classes)###获取label  one-hot编码\n",
    "        return all_data,all_label\n",
    "    def next_data(self):   ###python生成器，获取数据和label\n",
    "        while 1:\n",
    "            data_label = self.get_batch(self.index,self.batch_size)\n",
    "            self.index += self.batch_size\n",
    "            if self.index>self.all_num:\n",
    "                self.index = 0\n",
    "                random.shuffle(self.all_path)\n",
    "            yield data_label\n",
    "if __name__ == '__main__':\n",
    "    train_data = data_generate(train_path,img_h,img_w,n_channels,40)####定义生成器\n",
    "    test_data = data_generate(test_path,img_h,img_w,n_channels,20,flip=False)\n",
    "    input_data = Input(shape=(img_h,img_w,n_channels))\n",
    "    out = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(input_data)\n",
    "    out = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "    out = MaxPool2D(pool_size=(2,2),strides=(2,2))(out)\n",
    "    out = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(out)\n",
    "    out = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "    out = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(out)\n",
    "    out = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(out)\n",
    "    out = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    ####out = Dense(units=512,activation='relu')(out) ###数据集比较小，可不加这一层\n",
    "    out = Dense(units=5,activation='softmax')(out)\n",
    "    model = Model(inputs=input_data,outputs=out)\n",
    "    model.summary()\n",
    "    model_check = ModelCheckpoint('./model.h5',\n",
    "                                  monitor='val_loss',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=False,\n",
    "                                  mode='auto',\n",
    "                                  period=1)  ####用来验证每一epoch是否是最好的模型用来保存  val_loss\n",
    "    model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit_generator(train_data.next_data(),train_data.all_num//train_batch_size,100,callbacks=[model_check],\n",
    "                        validation_data=test_data.next_data(),validation_steps=test_data.all_num//test_batch_size)\n",
    " \n",
    "    model.save('./final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
