{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batches.meta', 'test_batch', 'data_batch_5', 'data_batch_2', 'data_batch_1', 'readme.html', 'data_batch_4', 'data_batch_3']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "CIFAR_DIR = \"./cifar-10-batches-py\"\n",
    "print (os.listdir(CIFAR_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"read data from data file.\"\"\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data = pickle.load(f,encoding='bytes')\n",
    "        return data[b'data'],data[b'labels']\n",
    "    \n",
    "class CifarData:\n",
    "    def __init__(self,filenames,need_shuffle):\n",
    "        all_data = []\n",
    "        all_lebels = []\n",
    "        for filename in filenames:\n",
    "            data,labels = load_data(filename)\n",
    "            all_data.append(data)\n",
    "            all_lebels.append(labels)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 -1\n",
    "        self._labels = np.hstack(all_lebels)\n",
    "        '''print (self._data.shape)\n",
    "        print (self._labels.shape)\n",
    "        '''\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def _shuffle_data(self):\n",
    "        #[0,1,2,3,4,5]-> [5,3,2,4,0,1]\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "        \n",
    "    def next_batch(self,batch_size):\n",
    "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data,batch_labels\n",
    "                \n",
    "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1,6)]\n",
    "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = CifarData(train_filenames,True)\n",
    "test_data = CifarData(test_filenames,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fly/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/fly/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None,3072])\n",
    "#[None]\n",
    "y = tf.placeholder(tf.int64,[None])\n",
    "\n",
    "# (3072,10)\n",
    "w = tf.get_variable('w',[x.get_shape()[-1], 10],\n",
    "                    initializer = tf.random_normal_initializer(0, 1))\n",
    "#(10, )\n",
    "b = tf.get_variable('b',[10],\n",
    "                    initializer = tf.constant_initializer(0.0))\n",
    "# [None,3072]*[3072,10] = [None,10]\n",
    "y_ = tf.matmul(x,w) + b\n",
    "\"\"\"\n",
    "# \n",
    "#\n",
    "#\n",
    "p_y = tf.nn.softmax(y_)\n",
    "#5 -> [0,0,0,0,0,1,0,0,0,0]\n",
    "y_one_hot = tf.one_hot(y,10,dtype=tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(y_one_hot - p_y))\n",
    "\"\"\"\n",
    "\n",
    "loss = tf.losses.sparse_softm ax_cross_entropy(labels=y, logits=y_)\n",
    "#y_ -> sofmax\n",
    "#y -> one_hot\n",
    "#loss = ylogy_\n",
    "#bool\n",
    "predict = tf.argmax(y_,1)\n",
    "# [1,0,1,1,1,0,0,0]\n",
    "correct_prediction = tf.equal(predict,y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 500,loss: 14.18746,acc: 0.20000\n",
      "[Train] Step: 1000,loss: 17.83725,acc: 0.05000\n",
      "[Train] Step: 1500,loss: 13.70461,acc: 0.25000\n",
      "[Train] Step: 2000,loss: 8.16724,acc: 0.30000\n",
      "[Train] Step: 2500,loss: 10.10342,acc: 0.10000\n",
      "[Train] Step: 3000,loss: 13.11383,acc: 0.15000\n",
      "[Train] Step: 3500,loss: 7.55707,acc: 0.30000\n",
      "[Train] Step: 4000,loss: 8.86350,acc: 0.35000\n",
      "[Train] Step: 4500,loss: 10.70248,acc: 0.10000\n",
      "[Train] Step: 5000,loss: 9.07404,acc: 0.30000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 5000, acc: 0.26400\n",
      "[Train] Step: 5500,loss: 9.49754,acc: 0.20000\n",
      "[Train] Step: 6000,loss: 7.15122,acc: 0.30000\n",
      "[Train] Step: 6500,loss: 6.55136,acc: 0.20000\n",
      "[Train] Step: 7000,loss: 7.39265,acc: 0.25000\n",
      "[Train] Step: 7500,loss: 5.17857,acc: 0.25000\n",
      "[Train] Step: 8000,loss: 7.03001,acc: 0.35000\n",
      "[Train] Step: 8500,loss: 7.03020,acc: 0.15000\n",
      "[Train] Step: 9000,loss: 4.89981,acc: 0.30000\n",
      "[Train] Step: 9500,loss: 5.80732,acc: 0.35000\n",
      "[Train] Step: 10000,loss: 6.71800,acc: 0.10000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 10000, acc: 0.27450\n",
      "[Train] Step: 10500,loss: 6.86164,acc: 0.35000\n",
      "[Train] Step: 11000,loss: 4.79677,acc: 0.35000\n",
      "[Train] Step: 11500,loss: 4.32773,acc: 0.15000\n",
      "[Train] Step: 12000,loss: 6.04482,acc: 0.20000\n",
      "[Train] Step: 12500,loss: 5.92314,acc: 0.20000\n",
      "[Train] Step: 13000,loss: 5.31508,acc: 0.35000\n",
      "[Train] Step: 13500,loss: 4.64022,acc: 0.35000\n",
      "[Train] Step: 14000,loss: 3.04465,acc: 0.50000\n",
      "[Train] Step: 14500,loss: 3.60383,acc: 0.40000\n",
      "[Train] Step: 15000,loss: 4.96018,acc: 0.25000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 15000, acc: 0.27400\n",
      "[Train] Step: 15500,loss: 5.57570,acc: 0.25000\n",
      "[Train] Step: 16000,loss: 6.66114,acc: 0.35000\n",
      "[Train] Step: 16500,loss: 3.58575,acc: 0.45000\n",
      "[Train] Step: 17000,loss: 4.13234,acc: 0.25000\n",
      "[Train] Step: 17500,loss: 4.96446,acc: 0.30000\n",
      "[Train] Step: 18000,loss: 4.26227,acc: 0.30000\n",
      "[Train] Step: 18500,loss: 3.68625,acc: 0.25000\n",
      "[Train] Step: 19000,loss: 4.68274,acc: 0.20000\n",
      "[Train] Step: 19500,loss: 3.91857,acc: 0.20000\n",
      "[Train] Step: 20000,loss: 4.31230,acc: 0.30000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 20000, acc: 0.27200\n",
      "[Train] Step: 20500,loss: 3.77916,acc: 0.35000\n",
      "[Train] Step: 21000,loss: 3.71140,acc: 0.45000\n",
      "[Train] Step: 21500,loss: 2.31298,acc: 0.50000\n",
      "[Train] Step: 22000,loss: 4.11782,acc: 0.30000\n",
      "[Train] Step: 22500,loss: 4.71518,acc: 0.40000\n",
      "[Train] Step: 23000,loss: 4.85330,acc: 0.25000\n",
      "[Train] Step: 23500,loss: 2.72129,acc: 0.40000\n",
      "[Train] Step: 24000,loss: 3.78755,acc: 0.30000\n",
      "[Train] Step: 24500,loss: 2.42173,acc: 0.45000\n",
      "[Train] Step: 25000,loss: 1.79416,acc: 0.40000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 25000, acc: 0.28800\n",
      "[Train] Step: 25500,loss: 5.16361,acc: 0.30000\n",
      "[Train] Step: 26000,loss: 4.22867,acc: 0.25000\n",
      "[Train] Step: 26500,loss: 3.78077,acc: 0.25000\n",
      "[Train] Step: 27000,loss: 3.54997,acc: 0.35000\n",
      "[Train] Step: 27500,loss: 3.87712,acc: 0.25000\n",
      "[Train] Step: 28000,loss: 5.23847,acc: 0.25000\n",
      "[Train] Step: 28500,loss: 3.43817,acc: 0.40000\n",
      "[Train] Step: 29000,loss: 3.16391,acc: 0.55000\n",
      "[Train] Step: 29500,loss: 4.64433,acc: 0.30000\n",
      "[Train] Step: 30000,loss: 2.99397,acc: 0.35000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 30000, acc: 0.29550\n",
      "[Train] Step: 30500,loss: 2.47744,acc: 0.40000\n",
      "[Train] Step: 31000,loss: 2.60362,acc: 0.45000\n",
      "[Train] Step: 31500,loss: 4.45866,acc: 0.20000\n",
      "[Train] Step: 32000,loss: 4.38136,acc: 0.25000\n",
      "[Train] Step: 32500,loss: 2.71510,acc: 0.30000\n",
      "[Train] Step: 33000,loss: 2.24481,acc: 0.45000\n",
      "[Train] Step: 33500,loss: 4.37868,acc: 0.25000\n",
      "[Train] Step: 34000,loss: 5.19819,acc: 0.30000\n",
      "[Train] Step: 34500,loss: 3.59608,acc: 0.20000\n",
      "[Train] Step: 35000,loss: 3.57409,acc: 0.25000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 35000, acc: 0.27600\n",
      "[Train] Step: 35500,loss: 3.58249,acc: 0.35000\n",
      "[Train] Step: 36000,loss: 3.75978,acc: 0.20000\n",
      "[Train] Step: 36500,loss: 3.63837,acc: 0.25000\n",
      "[Train] Step: 37000,loss: 3.47529,acc: 0.30000\n",
      "[Train] Step: 37500,loss: 4.35705,acc: 0.30000\n",
      "[Train] Step: 38000,loss: 2.81924,acc: 0.30000\n",
      "[Train] Step: 38500,loss: 3.06788,acc: 0.20000\n",
      "[Train] Step: 39000,loss: 2.79144,acc: 0.25000\n",
      "[Train] Step: 39500,loss: 3.73811,acc: 0.25000\n",
      "[Train] Step: 40000,loss: 2.58576,acc: 0.35000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 40000, acc: 0.27750\n",
      "[Train] Step: 40500,loss: 2.33069,acc: 0.40000\n",
      "[Train] Step: 41000,loss: 2.85890,acc: 0.25000\n",
      "[Train] Step: 41500,loss: 3.00053,acc: 0.25000\n",
      "[Train] Step: 42000,loss: 4.04821,acc: 0.20000\n",
      "[Train] Step: 42500,loss: 2.08862,acc: 0.45000\n",
      "[Train] Step: 43000,loss: 3.13092,acc: 0.20000\n",
      "[Train] Step: 43500,loss: 2.70564,acc: 0.25000\n",
      "[Train] Step: 44000,loss: 2.99433,acc: 0.35000\n",
      "[Train] Step: 44500,loss: 2.81755,acc: 0.20000\n",
      "[Train] Step: 45000,loss: 2.71321,acc: 0.30000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 45000, acc: 0.29900\n",
      "[Train] Step: 45500,loss: 3.10568,acc: 0.50000\n",
      "[Train] Step: 46000,loss: 2.32413,acc: 0.50000\n",
      "[Train] Step: 46500,loss: 3.60980,acc: 0.25000\n",
      "[Train] Step: 47000,loss: 3.35668,acc: 0.20000\n",
      "[Train] Step: 47500,loss: 4.01332,acc: 0.25000\n",
      "[Train] Step: 48000,loss: 2.71528,acc: 0.30000\n",
      "[Train] Step: 48500,loss: 3.02430,acc: 0.30000\n",
      "[Train] Step: 49000,loss: 2.93890,acc: 0.30000\n",
      "[Train] Step: 49500,loss: 2.27024,acc: 0.35000\n",
      "[Train] Step: 50000,loss: 3.16701,acc: 0.25000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 50000, acc: 0.27600\n",
      "[Train] Step: 50500,loss: 2.97678,acc: 0.30000\n",
      "[Train] Step: 51000,loss: 2.82032,acc: 0.30000\n",
      "[Train] Step: 51500,loss: 2.57712,acc: 0.40000\n",
      "[Train] Step: 52000,loss: 2.78811,acc: 0.30000\n",
      "[Train] Step: 52500,loss: 1.62217,acc: 0.50000\n",
      "[Train] Step: 53000,loss: 2.72728,acc: 0.45000\n",
      "[Train] Step: 53500,loss: 2.90880,acc: 0.25000\n",
      "[Train] Step: 54000,loss: 1.28961,acc: 0.60000\n",
      "[Train] Step: 54500,loss: 2.98579,acc: 0.30000\n",
      "[Train] Step: 55000,loss: 1.97109,acc: 0.35000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 55000, acc: 0.28700\n",
      "[Train] Step: 55500,loss: 1.84006,acc: 0.40000\n",
      "[Train] Step: 56000,loss: 2.18449,acc: 0.35000\n",
      "[Train] Step: 56500,loss: 2.30499,acc: 0.30000\n",
      "[Train] Step: 57000,loss: 3.46630,acc: 0.25000\n",
      "[Train] Step: 57500,loss: 3.33069,acc: 0.25000\n",
      "[Train] Step: 58000,loss: 2.73818,acc: 0.45000\n",
      "[Train] Step: 58500,loss: 3.23783,acc: 0.30000\n",
      "[Train] Step: 59000,loss: 3.31261,acc: 0.20000\n",
      "[Train] Step: 59500,loss: 2.25629,acc: 0.35000\n",
      "[Train] Step: 60000,loss: 1.85354,acc: 0.55000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 60000, acc: 0.30000\n",
      "[Train] Step: 60500,loss: 2.35165,acc: 0.45000\n",
      "[Train] Step: 61000,loss: 2.89940,acc: 0.35000\n",
      "[Train] Step: 61500,loss: 1.55709,acc: 0.45000\n",
      "[Train] Step: 62000,loss: 2.19603,acc: 0.30000\n",
      "[Train] Step: 62500,loss: 2.30684,acc: 0.35000\n",
      "[Train] Step: 63000,loss: 2.10309,acc: 0.60000\n",
      "[Train] Step: 63500,loss: 2.03011,acc: 0.35000\n",
      "[Train] Step: 64000,loss: 2.62875,acc: 0.25000\n",
      "[Train] Step: 64500,loss: 2.50279,acc: 0.35000\n",
      "[Train] Step: 65000,loss: 3.25783,acc: 0.35000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 65000, acc: 0.29600\n",
      "[Train] Step: 65500,loss: 2.42962,acc: 0.25000\n",
      "[Train] Step: 66000,loss: 2.14633,acc: 0.35000\n",
      "[Train] Step: 66500,loss: 2.54914,acc: 0.35000\n",
      "[Train] Step: 67000,loss: 1.83695,acc: 0.45000\n",
      "[Train] Step: 67500,loss: 2.12050,acc: 0.50000\n",
      "[Train] Step: 68000,loss: 1.97426,acc: 0.25000\n",
      "[Train] Step: 68500,loss: 2.29218,acc: 0.40000\n",
      "[Train] Step: 69000,loss: 2.85647,acc: 0.20000\n",
      "[Train] Step: 69500,loss: 1.87421,acc: 0.40000\n",
      "[Train] Step: 70000,loss: 1.76554,acc: 0.40000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 70000, acc: 0.29300\n",
      "[Train] Step: 70500,loss: 2.85659,acc: 0.25000\n",
      "[Train] Step: 71000,loss: 1.64793,acc: 0.50000\n",
      "[Train] Step: 71500,loss: 2.04767,acc: 0.30000\n",
      "[Train] Step: 72000,loss: 2.19946,acc: 0.45000\n",
      "[Train] Step: 72500,loss: 2.13089,acc: 0.40000\n",
      "[Train] Step: 73000,loss: 3.01583,acc: 0.20000\n",
      "[Train] Step: 73500,loss: 1.68649,acc: 0.40000\n",
      "[Train] Step: 74000,loss: 2.96457,acc: 0.25000\n",
      "[Train] Step: 74500,loss: 2.93858,acc: 0.35000\n",
      "[Train] Step: 75000,loss: 2.48913,acc: 0.30000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 75000, acc: 0.31550\n",
      "[Train] Step: 75500,loss: 2.01999,acc: 0.30000\n",
      "[Train] Step: 76000,loss: 3.62522,acc: 0.25000\n",
      "[Train] Step: 76500,loss: 1.89792,acc: 0.45000\n",
      "[Train] Step: 77000,loss: 2.38674,acc: 0.30000\n",
      "[Train] Step: 77500,loss: 2.59866,acc: 0.45000\n",
      "[Train] Step: 78000,loss: 2.36066,acc: 0.35000\n",
      "[Train] Step: 78500,loss: 2.52278,acc: 0.35000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 79000,loss: 2.55555,acc: 0.35000\n",
      "[Train] Step: 79500,loss: 3.88815,acc: 0.20000\n",
      "[Train] Step: 80000,loss: 2.07160,acc: 0.30000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 80000, acc: 0.32150\n",
      "[Train] Step: 80500,loss: 1.71088,acc: 0.45000\n",
      "[Train] Step: 81000,loss: 2.26151,acc: 0.35000\n",
      "[Train] Step: 81500,loss: 2.56246,acc: 0.25000\n",
      "[Train] Step: 82000,loss: 2.30971,acc: 0.45000\n",
      "[Train] Step: 82500,loss: 2.26381,acc: 0.25000\n",
      "[Train] Step: 83000,loss: 1.94749,acc: 0.45000\n",
      "[Train] Step: 83500,loss: 2.30377,acc: 0.40000\n",
      "[Train] Step: 84000,loss: 1.91806,acc: 0.60000\n",
      "[Train] Step: 84500,loss: 1.87767,acc: 0.45000\n",
      "[Train] Step: 85000,loss: 1.47350,acc: 0.50000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 85000, acc: 0.31100\n",
      "[Train] Step: 85500,loss: 2.56301,acc: 0.20000\n",
      "[Train] Step: 86000,loss: 1.97796,acc: 0.40000\n",
      "[Train] Step: 86500,loss: 2.28932,acc: 0.30000\n",
      "[Train] Step: 87000,loss: 2.80060,acc: 0.20000\n",
      "[Train] Step: 87500,loss: 2.53451,acc: 0.35000\n",
      "[Train] Step: 88000,loss: 2.43270,acc: 0.25000\n",
      "[Train] Step: 88500,loss: 1.95585,acc: 0.40000\n",
      "[Train] Step: 89000,loss: 2.48857,acc: 0.30000\n",
      "[Train] Step: 89500,loss: 2.15128,acc: 0.45000\n",
      "[Train] Step: 90000,loss: 1.88359,acc: 0.40000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 90000, acc: 0.31650\n",
      "[Train] Step: 90500,loss: 2.00470,acc: 0.40000\n",
      "[Train] Step: 91000,loss: 2.09207,acc: 0.35000\n",
      "[Train] Step: 91500,loss: 2.45226,acc: 0.30000\n",
      "[Train] Step: 92000,loss: 1.74521,acc: 0.50000\n",
      "[Train] Step: 92500,loss: 3.37559,acc: 0.15000\n",
      "[Train] Step: 93000,loss: 2.09467,acc: 0.40000\n",
      "[Train] Step: 93500,loss: 1.97230,acc: 0.45000\n",
      "[Train] Step: 94000,loss: 2.69477,acc: 0.40000\n",
      "[Train] Step: 94500,loss: 2.92589,acc: 0.30000\n",
      "[Train] Step: 95000,loss: 2.23962,acc: 0.20000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 95000, acc: 0.31100\n",
      "[Train] Step: 95500,loss: 2.73802,acc: 0.25000\n",
      "[Train] Step: 96000,loss: 2.84518,acc: 0.45000\n",
      "[Train] Step: 96500,loss: 1.91959,acc: 0.40000\n",
      "[Train] Step: 97000,loss: 2.45459,acc: 0.30000\n",
      "[Train] Step: 97500,loss: 2.15525,acc: 0.20000\n",
      "[Train] Step: 98000,loss: 2.15650,acc: 0.30000\n",
      "[Train] Step: 98500,loss: 1.60258,acc: 0.55000\n",
      "[Train] Step: 99000,loss: 1.94973,acc: 0.55000\n",
      "[Train] Step: 99500,loss: 2.36987,acc: 0.30000\n",
      "[Train] Step: 100000,loss: 2.52672,acc: 0.20000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test] Step: 100000, acc: 0.33550\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 10000\n",
    "test_steps = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val , acc_val,_ = sess.run(\n",
    "            [loss,accuracy,train_op],\n",
    "            feed_dict={\n",
    "                x: batch_data,y: batch_labels})\n",
    "        \"\"\"\n",
    "        for i in range(0, len(mnist.test.images)):\n",
    "  result = sess.run(correct_prediction, feed_dict={x: np.array([mnist.test.images[i]]), y_: np.array([mnist.test.labels[i]])})\n",
    "  if not result:\n",
    "    print('预测的值是：',sess.run(y, feed_dict={x: np.array([mnist.test.images[i]]), y_: np.array([mnist.test.labels[i]])}))\n",
    "    print('实际的值是：',sess.run(y_,feed_dict={x: np.array([mnist.test.images[i]]), y_: np.array([mnist.test.labels[i]])}))\n",
    "    one_pic_arr = np.reshape(mnist.test.images[i], (28, 28))\n",
    "    pic_matrix = np.matrix(one_pic_arr, dtype=\"float\")\n",
    "    plt.imshow(pic_matrix)\n",
    "    pylab.show()\n",
    "    break\n",
    " \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                     y_: mnist.test.labels})) \"\"\" \n",
    "        if (i+1) % 500 == 0:\n",
    "            print('[Train] Step: %d,loss: %4.5f,acc: %4.5f'  \\\n",
    "                  % (i+1,loss_val, acc_val))\n",
    "        if (i+1) % 5000 == 0:\n",
    "            test_data = CifarData(test_filenames,False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels  = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run([accuracy],feed_dict = {x: test_batch_data,y: test_batch_labels})\n",
    "                \n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test] Step: %d, acc: %4.5f' \\\n",
    "                  % (i+1 ,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
